#!/usr/bin/env sage
"""
Core experiments for lattice Gaussian MCMC - standalone version.
"""


# This file was *autogenerated* from the file experiments/run_core_experiments.sage
from sage.all_cmdline import *   # import sage library

_sage_const_60 = Integer(60); _sage_const_42 = Integer(42); _sage_const_40 = Integer(40); _sage_const_16 = Integer(16); _sage_const_64 = Integer(64); _sage_const_256 = Integer(256); _sage_const_0p5 = RealNumber('0.5'); _sage_const_1p0 = RealNumber('1.0'); _sage_const_2p0 = RealNumber('2.0'); _sage_const_5000 = Integer(5000); _sage_const_50000 = Integer(50000); _sage_const_0 = Integer(0); _sage_const_1 = Integer(1); _sage_const_2 = Integer(2); _sage_const_257 = Integer(257); _sage_const_12289 = Integer(12289); _sage_const_10p0 = RealNumber('10.0'); _sage_const_50p0 = RealNumber('50.0'); _sage_const_100p0 = RealNumber('100.0'); _sage_const_500 = Integer(500); _sage_const_10000 = Integer(10000); _sage_const_10 = Integer(10); _sage_const_50 = Integer(50); _sage_const_100 = Integer(100); _sage_const_1000 = Integer(1000); _sage_const_30 = Integer(30); _sage_const_1en10 = RealNumber('1e-10')
from sage.all import *
import numpy as np
import json
import time
from pathlib import Path

# Create directories
for d in ['results/samples', 'results/diagnostics', 'results/figures', 'results/tables']:
    Path(d).mkdir(parents=True, exist_ok=True)

print("LATTICE GAUSSIAN MCMC EXPERIMENTS")
print("="*_sage_const_60 )

# Set seeds
set_random_seed(_sage_const_42 )
np.random.seed(_sage_const_42 )


# 1. IDENTITY LATTICE EXPERIMENTS
print("\n1. IDENTITY LATTICE Z^n")
print("-"*_sage_const_40 )

identity_results = []

for n in [_sage_const_16 , _sage_const_64 , _sage_const_256 ]:
    for regime, factor in [('hard', _sage_const_0p5 ), ('near', _sage_const_1p0 ), ('smooth', _sage_const_2p0 )]:
        sigma = factor * sqrt(n).n()
        n_samples = min(_sage_const_5000 , _sage_const_50000  // n)
        
        print(f"\nn={n}, regime={regime}, σ={sigma:.2f}")
        
        # Sample from Z^n
        start = time.time()
        samples = []
        
        for _ in range(n_samples):
            # Direct discrete Gaussian sampling
            v = vector(ZZ, [Integer(round(normalvariate(_sage_const_0 , sigma))) for _ in range(n)])
            samples.append(v)
        
        elapsed = time.time() - start
        
        # Convert to array
        samples_array = np.array([[int(x) for x in v] for v in samples])
        norms = np.linalg.norm(samples_array, axis=_sage_const_1 )
        
        result = {
            'lattice': 'identity',
            'n': n,
            'sigma': float(sigma),
            'regime': regime,
            'n_samples': n_samples,
            'time': elapsed,
            'rate': n_samples/elapsed,
            'mean_norm': float(np.mean(norms)),
            'std_norm': float(np.std(norms))
        }
        
        identity_results.append(result)
        print(f"  Rate: {result['rate']:.1f} samples/sec")
        print(f"  Mean norm: {result['mean_norm']:.2f}")
        
        # Save samples
        np.savez_compressed(
            f'results/samples/identity_n{n}_{regime}.npz',
            samples=samples_array,
            norms=norms
        )

# Save identity results
with open('results/diagnostics/identity_results.json', 'w') as f:
    json.dump(identity_results, f, indent=_sage_const_2 )


# 2. NTRU LATTICE EXPERIMENTS  
print("\n\n2. NTRU LATTICES")
print("-"*_sage_const_40 )

# Simple NTRU implementation
class SimpleNTRU:
    def __init__(self, n, q):
        self.n = n
        self.q = q
        
        # Polynomial ring
        R = PolynomialRing(ZZ, names=('x',)); (x,) = R._first_ngens(1)
        self.R = R.quotient(x**n + _sage_const_1 )
        
        # Generate simple keys
        self.f = self.R([_sage_const_1 ] + [choice([-_sage_const_1 ,_sage_const_0 ,_sage_const_1 ]) for _ in range(n-_sage_const_1 )])
        self.g = self.R([choice([-_sage_const_1 ,_sage_const_0 ,_sage_const_1 ]) for _ in range(n)])
        
        # Basis (simplified - just use standard form)
        I_n = identity_matrix(ZZ, n)
        Z_n = zero_matrix(ZZ, n)
        
        # Random h for public key simulation
        h_coeffs = [randint(_sage_const_0 , q-_sage_const_1 ) for _ in range(n)]
        H = matrix(ZZ, n, n)
        for i in range(n):
            for j in range(n):
                H[i,j] = h_coeffs[(j-i) % n]
        
        self.basis = block_matrix([
            [q * I_n, Z_n],
            [H, I_n]
        ])
        
        # Compute simple GS norms
        self.gs_min = _sage_const_1p0 
        self.gs_max = float(q)

ntru_results = []

for n, q in [(_sage_const_64 , _sage_const_257 ), (_sage_const_64 , _sage_const_12289 )]:
    print(f"\nNTRU: n={n}, q={q}")
    
    ntru = SimpleNTRU(n, q)
    print(f"  GS ratio: {ntru.gs_max/ntru.gs_min:.1f}")
    
    for regime, sigma in [('hard', _sage_const_10p0 ), ('medium', _sage_const_50p0 ), ('smooth', _sage_const_100p0 )]:
        n_samples = _sage_const_500 
        
        print(f"\n  Regime: {regime}, σ={sigma}")
        
        # Sample using CVP approximation
        start = time.time()
        samples = []
        
        for _ in range(n_samples):
            # Sample continuous Gaussian
            y = vector(RDF, [normalvariate(_sage_const_0 , sigma) for _ in range(_sage_const_2 *n)])
            
            # Approximate CVP (Babai)
            try:
                coeffs = ntru.basis.solve_left(y)
                rounded = vector(ZZ, [round(c) for c in coeffs])
                v = ntru.basis * rounded
                samples.append(v)
            except:
                # Fallback to random
                v = vector(ZZ, _sage_const_2 *n)
                samples.append(v)
        
        elapsed = time.time() - start
        
        # Convert to array
        samples_array = np.array([[int(x) for x in v] for v in samples])
        norms = np.linalg.norm(samples_array, axis=_sage_const_1 )
        
        result = {
            'lattice': 'ntru',
            'n': n,
            'q': q,
            'sigma': float(sigma),
            'regime': regime,
            'n_samples': n_samples,
            'time': elapsed,
            'rate': n_samples/elapsed,
            'mean_norm': float(np.mean(norms)),
            'std_norm': float(np.std(norms)),
            'gs_ratio': ntru.gs_max/ntru.gs_min
        }
        
        ntru_results.append(result)
        print(f"    Rate: {result['rate']:.1f} samples/sec")
        
        # Save samples
        np.savez_compressed(
            f'results/samples/ntru_n{n}_q{q}_{regime}.npz',
            samples=samples_array,
            norms=norms
        )

# Save NTRU results
with open('results/diagnostics/ntru_results.json', 'w') as f:
    json.dump(ntru_results, f, indent=_sage_const_2 )


# 3. CONVERGENCE ANALYSIS
print("\n\n3. CONVERGENCE ANALYSIS")
print("-"*_sage_const_40 )

# Simple TVD computation for identity lattice
n = _sage_const_16 
sigma = sqrt(n).n()

print(f"\nConvergence for Z^{n}, σ={sigma:.2f}")

# Reference distribution (many samples)
ref_norms = []
for _ in range(_sage_const_10000 ):
    v = vector([normalvariate(_sage_const_0 , sigma) for _ in range(n)])
    ref_norms.append(v.norm())

ref_norms = np.array(ref_norms)

# Track TVD over iterations
iterations = [_sage_const_10 , _sage_const_50 , _sage_const_100 , _sage_const_500 , _sage_const_1000 , _sage_const_5000 ]
tvd_values = []

for n_iter in iterations:
    sample_norms = []
    for _ in range(n_iter):
        v = vector([normalvariate(_sage_const_0 , sigma) for _ in range(n)])
        sample_norms.append(v.norm())
    
    sample_norms = np.array(sample_norms)
    
    # Compute TVD
    bins = np.linspace(_sage_const_0 , max(ref_norms.max(), sample_norms.max()), _sage_const_30 )
    hist_ref, _ = np.histogram(ref_norms, bins=bins, density=True)
    hist_sample, _ = np.histogram(sample_norms, bins=bins, density=True) 
    
    # Normalize
    hist_ref = hist_ref / (hist_ref.sum() + _sage_const_1en10 )
    hist_sample = hist_sample / (hist_sample.sum() + _sage_const_1en10 )
    
    tvd = _sage_const_0p5  * np.abs(hist_ref - hist_sample).sum()
    tvd_values.append(float(tvd))
    
    print(f"  Iter {n_iter}: TVD = {tvd:.4f}")

# Save convergence data
conv_data = {
    'lattice': 'identity',
    'n': n,
    'sigma': float(sigma),
    'iterations': iterations,
    'tvd_values': tvd_values
}

with open('results/diagnostics/convergence_data.json', 'w') as f:
    json.dump(conv_data, f, indent=_sage_const_2 )


# 4. SUMMARY
print("\n\n4. EXPERIMENT SUMMARY")
print("-"*_sage_const_60 )

all_results = identity_results + ntru_results

print(f"\nTotal experiments run: {len(all_results)}")
print("\nResults by lattice type:")
print(f"  Identity: {len(identity_results)} experiments")
print(f"  NTRU: {len(ntru_results)} experiments")

# Performance summary
print("\nPerformance Summary (samples/sec):")
print("-"*_sage_const_40 )
print(f"{'Lattice':<10} {'Min':<10} {'Max':<10} {'Mean':<10}")
print("-"*_sage_const_40 )

for lattice_type in ['identity', 'ntru']:
    rates = [r['rate'] for r in all_results if r['lattice'] == lattice_type]
    if rates:
        print(f"{lattice_type:<10} {min(rates):<10.1f} {max(rates):<10.1f} {np.mean(rates):<10.1f}")

# Save full summary
summary = {
    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
    'total_experiments': len(all_results),
    'experiments': all_results,
    'convergence': conv_data
}

with open('results/diagnostics/full_summary.json', 'w') as f:
    json.dump(summary, f, indent=_sage_const_2 )

print("\n✅ ALL EXPERIMENTS COMPLETED")
print("\nResults saved in:")
print("  - results/samples/      (raw sample data)")
print("  - results/diagnostics/  (experiment metrics)")
print("  - results/diagnostics/full_summary.json")

