{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Exploratory Data Analysis for Lattice Gaussian MCMC\n",
    "\n",
    "This notebook provides interactive tools for exploring experimental results from lattice Gaussian sampling experiments.\n",
    "\n",
    "## Contents\n",
    "1. **Data Loading and Preprocessing**\n",
    "2. **Visual Inspection Tools**\n",
    "3. **Diagnostic Analysis**\n",
    "4. **Rapid Prototyping**\n",
    "5. **Documentation and Insights**\n",
    "6. **Export and Reproducibility**"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Standard imports\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport json\nimport pickle\nfrom datetime import datetime\n\n# Interactive widgets\nimport ipywidgets as widgets\nfrom IPython.display import display, HTML, Markdown\n\n# Plotly for interactive plots\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\n# Project imports\nimport sys\nsys.path.append('..')\nfrom src.visualization.plots import PlottingTools\nfrom src.diagnostics.convergence import ConvergenceDiagnostics\nfrom src.diagnostics.spectral import SpectralAnalysis\nfrom src.diagnostics.mcmc import MCMCDiagnostics\n\n# Configure plotting\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette('husl')\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nprint(f\"Notebook initialized at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Data Loading and Preprocessing\n\nThe `DataLoader` class provides flexible data loading with automatic detection of file formats and experiment types.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class DataLoader:\n    \"\"\"Interactive data loader for experimental results.\"\"\"\n    \n    def __init__(self, base_path='../results'):\n        self.base_path = Path(base_path)\n        self.data_cache = {}\n        \n    def list_experiments(self):\n        \"\"\"List all available experiment results.\"\"\"\n        experiments = []\n        for exp_type in ['samples', 'diagnostics', 'logs']:\n            exp_dir = self.base_path / exp_type\n            if exp_dir.exists():\n                for file in exp_dir.glob('**/*'):\n                    if file.is_file():\n                        experiments.append({\n                            'type': exp_type,\n                            'path': str(file.relative_to(self.base_path)),\n                            'size': f\"{file.stat().st_size / 1024:.1f} KB\",\n                            'modified': datetime.fromtimestamp(file.stat().st_mtime).strftime('%Y-%m-%d %H:%M')\n                        })\n        return pd.DataFrame(experiments)\n    \n    def load_samples(self, path):\n        \"\"\"Load sample data from various formats.\"\"\"\n        full_path = self.base_path / path\n        \n        if path in self.data_cache:\n            return self.data_cache[path]\n        \n        if full_path.suffix == '.npy':\n            data = np.load(full_path)\n        elif full_path.suffix == '.npz':\n            data = dict(np.load(full_path))\n        elif full_path.suffix == '.pkl':\n            with open(full_path, 'rb') as f:\n                data = pickle.load(f)\n        elif full_path.suffix == '.json':\n            with open(full_path, 'r') as f:\n                data = json.load(f)\n        else:\n            raise ValueError(f\"Unsupported file format: {full_path.suffix}\")\n        \n        self.data_cache[path] = data\n        return data\n    \n    def create_interactive_loader(self):\n        \"\"\"Create interactive file browser widget.\"\"\"\n        experiments_df = self.list_experiments()\n        \n        # Filter widgets\n        type_filter = widgets.Dropdown(\n            options=['All'] + list(experiments_df['type'].unique()),\n            value='All',\n            description='Type:'\n        )\n        \n        search_box = widgets.Text(\n            placeholder='Search experiments...',\n            description='Search:'\n        )\n        \n        # Output area\n        output = widgets.Output()\n        file_info = widgets.HTML()\n        \n        def update_list(*args):\n            with output:\n                output.clear_output()\n                \n                # Apply filters\n                df = experiments_df.copy()\n                if type_filter.value != 'All':\n                    df = df[df['type'] == type_filter.value]\n                if search_box.value:\n                    mask = df['path'].str.contains(search_box.value, case=False)\n                    df = df[mask]\n                \n                display(df)\n        \n        def load_selected():\n            \"\"\"Load selected file.\"\"\"\n            selection = widgets.Text(\n                placeholder='Enter path from above',\n                description='Path:'\n            )\n            load_btn = widgets.Button(description='Load')\n            \n            def on_load(b):\n                try:\n                    data = self.load_samples(selection.value)\n                    file_info.value = f\"<b>Loaded:</b> {selection.value}<br>\"\n                    file_info.value += f\"<b>Type:</b> {type(data).__name__}<br>\"\n                    if isinstance(data, np.ndarray):\n                        file_info.value += f\"<b>Shape:</b> {data.shape}<br>\"\n                        file_info.value += f\"<b>Dtype:</b> {data.dtype}\"\n                    elif isinstance(data, dict):\n                        file_info.value += f\"<b>Keys:</b> {list(data.keys())}\"\n                except Exception as e:\n                    file_info.value = f\"<b style='color:red'>Error:</b> {str(e)}\"\n            \n            load_btn.on_click(on_load)\n            display(widgets.HBox([selection, load_btn]))\n        \n        # Set up event handlers\n        type_filter.observe(update_list, 'value')\n        search_box.observe(update_list, 'value')\n        \n        # Initial display\n        update_list()\n        \n        # Layout\n        display(widgets.VBox([\n            widgets.HBox([type_filter, search_box]),\n            output,\n            widgets.Button(description='Load Selected', on_click=lambda b: load_selected()),\n            file_info\n        ]))\n        \n        return self\n\n# Initialize data loader\nloader = DataLoader()\nloader.create_interactive_loader()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Visual Inspection Tools\n\nThe `InteractiveVisualizer` provides dynamic exploration of MCMC chains, distributions, and convergence behavior.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class InteractiveVisualizer:\n    \"\"\"Interactive visualization tools for MCMC analysis.\"\"\"\n    \n    def __init__(self, samples=None):\n        self.samples = samples\n        self.current_plot = None\n        \n    def set_samples(self, samples):\n        \"\"\"Update the samples for visualization.\"\"\"\n        self.samples = samples\n        if isinstance(samples, dict):\n            print(f\"Loaded samples with keys: {list(samples.keys())}\")\n        elif isinstance(samples, np.ndarray):\n            print(f\"Loaded array with shape: {samples.shape}\")\n    \n    def trace_plot_interactive(self):\n        \"\"\"Interactive trace plot with dimension selection.\"\"\"\n        if self.samples is None:\n            print(\"No samples loaded. Use set_samples() first.\")\n            return\n        \n        # Handle different sample formats\n        if isinstance(self.samples, dict):\n            chains = self.samples.get('samples', self.samples.get('chain', None))\n        else:\n            chains = self.samples\n        \n        if chains is None:\n            print(\"Could not find sample chains in the data.\")\n            return\n        \n        # Ensure 3D shape: (n_chains, n_samples, n_dims)\n        if chains.ndim == 2:\n            chains = chains[np.newaxis, :]\n        elif chains.ndim == 1:\n            chains = chains[np.newaxis, :, np.newaxis]\n        \n        n_chains, n_samples, n_dims = chains.shape\n        \n        # Interactive controls\n        dim_slider = widgets.IntSlider(\n            value=0, min=0, max=n_dims-1,\n            description='Dimension:', continuous_update=False\n        )\n        \n        chain_select = widgets.SelectMultiple(\n            options=[(f'Chain {i}', i) for i in range(n_chains)],\n            value=list(range(min(4, n_chains))),\n            description='Chains:'\n        )\n        \n        burnin_slider = widgets.IntSlider(\n            value=0, min=0, max=n_samples//2,\n            description='Burn-in:', continuous_update=False\n        )\n        \n        plot_output = widgets.Output()\n        \n        def update_plot(*args):\n            with plot_output:\n                plot_output.clear_output(wait=True)\n                \n                fig = make_subplots(\n                    rows=2, cols=2,\n                    subplot_titles=('Trace Plot', 'Running Mean', \n                                  'Autocorrelation', 'Density'),\n                    specs=[[{'secondary_y': False}, {'secondary_y': False}],\n                           [{'secondary_y': False}, {'secondary_y': False}]]\n                )\n                \n                dim = dim_slider.value\n                burnin = burnin_slider.value\n                \n                colors = px.colors.qualitative.Plotly\n                \n                for i, chain_idx in enumerate(chain_select.value):\n                    color = colors[i % len(colors)]\n                    chain_data = chains[chain_idx, burnin:, dim]\n                    \n                    # Trace plot\n                    fig.add_trace(\n                        go.Scatter(y=chain_data, mode='lines', \n                                 name=f'Chain {chain_idx}',\n                                 line=dict(color=color, width=1),\n                                 opacity=0.7),\n                        row=1, col=1\n                    )\n                    \n                    # Running mean\n                    running_mean = pd.Series(chain_data).expanding().mean()\n                    fig.add_trace(\n                        go.Scatter(y=running_mean, mode='lines',\n                                 name=f'Chain {chain_idx}',\n                                 line=dict(color=color, width=2),\n                                 showlegend=False),\n                        row=1, col=2\n                    )\n                    \n                    # Autocorrelation\n                    max_lag = min(100, len(chain_data) // 4)\n                    acf = [pd.Series(chain_data).autocorr(lag=k) \n                           for k in range(max_lag)]\n                    fig.add_trace(\n                        go.Scatter(y=acf, mode='lines',\n                                 name=f'Chain {chain_idx}',\n                                 line=dict(color=color, width=2),\n                                 showlegend=False),\n                        row=2, col=1\n                    )\n                    \n                    # Density\n                    fig.add_trace(\n                        go.Histogram(x=chain_data, name=f'Chain {chain_idx}',\n                                   opacity=0.6, histnorm='probability density',\n                                   marker_color=color, showlegend=False),\n                        row=2, col=2\n                    )\n                \n                # Update layout\n                fig.update_xaxes(title_text=\"Iteration\", row=1, col=1)\n                fig.update_xaxes(title_text=\"Iteration\", row=1, col=2)\n                fig.update_xaxes(title_text=\"Lag\", row=2, col=1)\n                fig.update_xaxes(title_text=\"Value\", row=2, col=2)\n                \n                fig.update_yaxes(title_text=\"Value\", row=1, col=1)\n                fig.update_yaxes(title_text=\"Running Mean\", row=1, col=2)\n                fig.update_yaxes(title_text=\"ACF\", row=2, col=1)\n                fig.update_yaxes(title_text=\"Density\", row=2, col=2)\n                \n                fig.update_layout(\n                    height=800,\n                    title_text=f\"MCMC Diagnostics - Dimension {dim}\",\n                    showlegend=True\n                )\n                \n                fig.show()\n        \n        # Connect controls\n        dim_slider.observe(update_plot, 'value')\n        chain_select.observe(update_plot, 'value')\n        burnin_slider.observe(update_plot, 'value')\n        \n        # Initial plot\n        update_plot()\n        \n        # Display\n        display(widgets.VBox([\n            widgets.HBox([dim_slider, burnin_slider]),\n            chain_select,\n            plot_output\n        ]))\n    \n    def pairwise_scatter(self):\n        \"\"\"Interactive pairwise scatter plots.\"\"\"\n        if self.samples is None:\n            print(\"No samples loaded.\")\n            return\n        \n        # Extract samples\n        if isinstance(self.samples, dict):\n            data = self.samples.get('samples', self.samples.get('chain', None))\n        else:\n            data = self.samples\n        \n        if data.ndim == 3:\n            # Flatten chains\n            data = data.reshape(-1, data.shape[-1])\n        \n        n_samples, n_dims = data.shape\n        \n        # Dimension selection\n        dim_select = widgets.SelectMultiple(\n            options=[(f'Dim {i}', i) for i in range(n_dims)],\n            value=list(range(min(5, n_dims))),\n            description='Dimensions:',\n            rows=min(10, n_dims)\n        )\n        \n        subsample_slider = widgets.IntSlider(\n            value=min(1000, n_samples),\n            min=100, max=min(5000, n_samples),\n            description='Subsample:'\n        )\n        \n        plot_output = widgets.Output()\n        \n        def update_plot(*args):\n            with plot_output:\n                plot_output.clear_output(wait=True)\n                \n                selected_dims = list(dim_select.value)\n                n_selected = len(selected_dims)\n                \n                if n_selected < 2:\n                    print(\"Select at least 2 dimensions.\")\n                    return\n                \n                # Subsample data\n                idx = np.random.choice(n_samples, subsample_slider.value, replace=False)\n                plot_data = data[idx][:, selected_dims]\n                \n                # Create pairwise scatter matrix\n                fig = make_subplots(\n                    rows=n_selected, cols=n_selected,\n                    shared_xaxes=True, shared_yaxes=True,\n                    horizontal_spacing=0.02, vertical_spacing=0.02\n                )\n                \n                for i in range(n_selected):\n                    for j in range(n_selected):\n                        if i == j:\n                            # Diagonal: histogram\n                            fig.add_trace(\n                                go.Histogram(x=plot_data[:, i], \n                                           histnorm='probability density',\n                                           showlegend=False),\n                                row=i+1, col=j+1\n                            )\n                        else:\n                            # Off-diagonal: scatter\n                            fig.add_trace(\n                                go.Scatter(x=plot_data[:, j], y=plot_data[:, i],\n                                         mode='markers', marker=dict(size=3, opacity=0.5),\n                                         showlegend=False),\n                                row=i+1, col=j+1\n                            )\n                \n                # Labels\n                for i in range(n_selected):\n                    fig.update_xaxes(title_text=f\"Dim {selected_dims[i]}\", \n                                   row=n_selected, col=i+1)\n                    fig.update_yaxes(title_text=f\"Dim {selected_dims[i]}\", \n                                   row=i+1, col=1)\n                \n                fig.update_layout(\n                    height=150*n_selected,\n                    width=150*n_selected,\n                    title_text=\"Pairwise Scatter Matrix\"\n                )\n                \n                fig.show()\n        \n        # Connect and display\n        dim_select.observe(update_plot, 'value')\n        subsample_slider.observe(update_plot, 'value')\n        \n        update_plot()\n        \n        display(widgets.VBox([\n            widgets.HBox([dim_select, subsample_slider]),\n            plot_output\n        ]))\n    \n    def spectral_density_plot(self):\n        \"\"\"Interactive spectral density visualization.\"\"\"\n        if self.samples is None:\n            print(\"No samples loaded.\")\n            return\n            \n        # Extract samples\n        if isinstance(self.samples, dict):\n            data = self.samples.get('samples', self.samples.get('chain', None))\n        else:\n            data = self.samples\n            \n        if data.ndim == 3:\n            n_chains, n_samples, n_dims = data.shape\n        else:\n            data = data[np.newaxis, :]\n            n_chains, n_samples, n_dims = data.shape\n        \n        # Controls\n        dim_slider = widgets.IntSlider(\n            value=0, min=0, max=n_dims-1,\n            description='Dimension:'\n        )\n        \n        chain_slider = widgets.IntSlider(\n            value=0, min=0, max=n_chains-1,\n            description='Chain:'\n        )\n        \n        window_dropdown = widgets.Dropdown(\n            options=['hann', 'hamming', 'blackman', 'bartlett'],\n            value='hann',\n            description='Window:'\n        )\n        \n        plot_output = widgets.Output()\n        \n        def update_plot(*args):\n            with plot_output:\n                plot_output.clear_output(wait=True)\n                \n                chain_data = data[chain_slider.value, :, dim_slider.value]\n                \n                # Compute spectral density\n                from scipy import signal\n                freqs, psd = signal.periodogram(chain_data, \n                                               window=window_dropdown.value)\n                \n                # Create plot\n                fig = go.Figure()\n                \n                fig.add_trace(\n                    go.Scatter(x=freqs, y=psd, mode='lines',\n                             name='Spectral Density')\n                )\n                \n                fig.update_xaxes(title_text=\"Frequency\", type=\"log\")\n                fig.update_yaxes(title_text=\"Power Spectral Density\", type=\"log\")\n                \n                fig.update_layout(\n                    title_text=f\"Spectral Density - Chain {chain_slider.value}, Dim {dim_slider.value}\",\n                    height=500\n                )\n                \n                fig.show()\n                \n                # Additional info\n                print(f\"Effective sample size estimate: {len(chain_data) / (1 + 2*sum(pd.Series(chain_data).autocorr(lag=k) for k in range(1, 50))):.1f}\")\n        \n        # Connect and display\n        dim_slider.observe(update_plot, 'value')\n        chain_slider.observe(update_plot, 'value')\n        window_dropdown.observe(update_plot, 'value')\n        \n        update_plot()\n        \n        display(widgets.VBox([\n            widgets.HBox([dim_slider, chain_slider, window_dropdown]),\n            plot_output\n        ]))\n\n# Create visualizer instance\nviz = InteractiveVisualizer()\n\n# Example: Load and visualize synthetic data\nsynthetic_data = np.random.randn(2, 1000, 5)  # 2 chains, 1000 samples, 5 dimensions\nviz.set_samples(synthetic_data)\nviz.trace_plot_interactive()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Diagnostic Analysis\n\nThe `DiagnosticAnalyzer` provides comprehensive MCMC diagnostics with interactive controls.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class DiagnosticAnalyzer:\n    \"\"\"Comprehensive diagnostic analysis for MCMC chains.\"\"\"\n    \n    def __init__(self):\n        self.results = {}\n        \n    def analyze_convergence(self, samples, burn_in=0.1):\n        \"\"\"Run comprehensive convergence diagnostics.\"\"\"\n        if isinstance(samples, dict):\n            chains = samples.get('samples', samples.get('chain', None))\n        else:\n            chains = samples\n            \n        if chains.ndim == 2:\n            chains = chains[np.newaxis, :]\n        \n        n_chains, n_samples, n_dims = chains.shape\n        burn_in_idx = int(n_samples * burn_in)\n        \n        # Create diagnostic dashboard\n        tab_contents = []\n        tab_titles = []\n        \n        # 1. Summary statistics\n        summary_output = widgets.Output()\n        with summary_output:\n            print(\"=== MCMC Chain Summary ===\")\n            print(f\"Number of chains: {n_chains}\")\n            print(f\"Number of samples per chain: {n_samples}\")\n            print(f\"Number of dimensions: {n_dims}\")\n            print(f\"Burn-in samples: {burn_in_idx}\")\n            print()\n            \n            # Basic statistics\n            post_burnin = chains[:, burn_in_idx:, :]\n            print(\"Post burn-in statistics:\")\n            print(f\"Mean: {np.mean(post_burnin, axis=(0,1))[:5]}...\")\n            print(f\"Std: {np.std(post_burnin, axis=(0,1))[:5]}...\")\n            \n        tab_contents.append(summary_output)\n        tab_titles.append(\"Summary\")\n        \n        # 2. Gelman-Rubin diagnostic\n        gr_output = widgets.Output()\n        dim_select_gr = widgets.IntSlider(\n            value=0, min=0, max=n_dims-1,\n            description='Dimension:'\n        )\n        \n        def update_gr(*args):\n            with gr_output:\n                gr_output.clear_output(wait=True)\n                \n                if n_chains < 2:\n                    print(\"Need at least 2 chains for Gelman-Rubin diagnostic.\")\n                    return\n                \n                dim = dim_select_gr.value\n                chain_data = chains[:, burn_in_idx:, dim]\n                \n                # Calculate R-hat\n                n = chain_data.shape[1]\n                chain_means = np.mean(chain_data, axis=1)\n                chain_vars = np.var(chain_data, axis=1, ddof=1)\n                \n                B = n * np.var(chain_means, ddof=1)\n                W = np.mean(chain_vars)\n                var_plus = ((n-1)*W + B) / n\n                R_hat = np.sqrt(var_plus / W)\n                \n                print(f\"Gelman-Rubin R-hat for dimension {dim}: {R_hat:.4f}\")\n                print(\"(Values close to 1.0 indicate convergence)\")\n                \n                # Plot split R-hat over iterations\n                split_points = np.linspace(burn_in_idx, n_samples-1, 50, dtype=int)\n                r_hats = []\n                \n                for sp in split_points:\n                    if sp - burn_in_idx > 10:\n                        data_slice = chains[:, burn_in_idx:sp, dim]\n                        n_slice = data_slice.shape[1]\n                        means = np.mean(data_slice, axis=1)\n                        vars = np.var(data_slice, axis=1, ddof=1)\n                        B = n_slice * np.var(means, ddof=1)\n                        W = np.mean(vars)\n                        var_plus = ((n_slice-1)*W + B) / n_slice\n                        r_hats.append(np.sqrt(var_plus / W))\n                    else:\n                        r_hats.append(np.nan)\n                \n                fig = go.Figure()\n                fig.add_trace(go.Scatter(x=split_points, y=r_hats, mode='lines'))\n                fig.add_hline(y=1.1, line_dash=\"dash\", line_color=\"red\",\n                            annotation_text=\"R-hat = 1.1\")\n                fig.update_layout(\n                    title=\"R-hat vs Chain Length\",\n                    xaxis_title=\"Iteration\",\n                    yaxis_title=\"R-hat\",\n                    height=400\n                )\n                fig.show()\n        \n        dim_select_gr.observe(update_gr, 'value')\n        update_gr()\n        \n        gr_tab = widgets.VBox([dim_select_gr, gr_output])\n        tab_contents.append(gr_tab)\n        tab_titles.append(\"Gelman-Rubin\")\n        \n        # 3. Effective Sample Size\n        ess_output = widgets.Output()\n        \n        with ess_output:\n            print(\"=== Effective Sample Size ===\")\n            ess_values = []\n            \n            for dim in range(min(10, n_dims)):\n                # Simple ESS estimate\n                chain_data = chains[0, burn_in_idx:, dim]\n                acf_sum = 0\n                for lag in range(1, min(100, len(chain_data)//4)):\n                    acf = pd.Series(chain_data).autocorr(lag=lag)\n                    if acf < 0.05:\n                        break\n                    acf_sum += acf\n                \n                ess = len(chain_data) / (1 + 2*acf_sum)\n                ess_values.append(ess)\n                print(f\"Dimension {dim}: ESS = {ess:.1f} ({ess/len(chain_data)*100:.1f}%)\")\n            \n            # Plot ESS\n            fig = go.Figure()\n            fig.add_trace(go.Bar(x=list(range(len(ess_values))), y=ess_values))\n            fig.update_layout(\n                title=\"Effective Sample Size by Dimension\",\n                xaxis_title=\"Dimension\",\n                yaxis_title=\"ESS\",\n                height=400\n            )\n            fig.show()\n            \n        tab_contents.append(ess_output)\n        tab_titles.append(\"ESS\")\n        \n        # 4. Geweke diagnostic\n        geweke_output = widgets.Output()\n        chain_select = widgets.IntSlider(\n            value=0, min=0, max=n_chains-1,\n            description='Chain:'\n        )\n        \n        def update_geweke(*args):\n            with geweke_output:\n                geweke_output.clear_output(wait=True)\n                \n                chain_idx = chain_select.value\n                chain_data = chains[chain_idx, burn_in_idx:, :]\n                \n                # Geweke z-scores\n                n = chain_data.shape[0]\n                first_prop = 0.1\n                last_prop = 0.5\n                \n                first_n = int(n * first_prop)\n                last_n = int(n * last_prop)\n                \n                z_scores = []\n                for dim in range(min(20, n_dims)):\n                    first_mean = np.mean(chain_data[:first_n, dim])\n                    last_mean = np.mean(chain_data[-last_n:, dim])\n                    \n                    # Estimate spectral densities at zero\n                    first_var = np.var(chain_data[:first_n, dim])\n                    last_var = np.var(chain_data[-last_n:, dim])\n                    \n                    se = np.sqrt(first_var/first_n + last_var/last_n)\n                    z = (first_mean - last_mean) / se\n                    z_scores.append(z)\n                \n                # Plot\n                fig = go.Figure()\n                fig.add_trace(go.Scatter(\n                    x=list(range(len(z_scores))),\n                    y=z_scores,\n                    mode='markers+lines'\n                ))\n                fig.add_hline(y=1.96, line_dash=\"dash\", line_color=\"red\")\n                fig.add_hline(y=-1.96, line_dash=\"dash\", line_color=\"red\")\n                fig.update_layout(\n                    title=f\"Geweke Z-scores - Chain {chain_idx}\",\n                    xaxis_title=\"Dimension\",\n                    yaxis_title=\"Z-score\",\n                    height=400\n                )\n                fig.show()\n                \n                print(f\"Dimensions outside 95% CI: {sum(abs(z) > 1.96 for z in z_scores)}/{len(z_scores)}\")\n        \n        chain_select.observe(update_geweke, 'value')\n        update_geweke()\n        \n        geweke_tab = widgets.VBox([chain_select, geweke_output])\n        tab_contents.append(geweke_tab)\n        tab_titles.append(\"Geweke\")\n        \n        # Create tabs\n        tabs = widgets.Tab(children=tab_contents)\n        for i, title in enumerate(tab_titles):\n            tabs.set_title(i, title)\n            \n        display(tabs)\n        \n        return self.results\n    \n    def compare_samplers(self, results_dict):\n        \"\"\"Compare diagnostics across different samplers.\"\"\"\n        output = widgets.Output()\n        \n        with output:\n            # Create comparison plots\n            fig = make_subplots(\n                rows=2, cols=2,\n                subplot_titles=('Acceptance Rate', 'ESS per Second', \n                              'R-hat Distribution', 'Autocorrelation')\n            )\n            \n            colors = px.colors.qualitative.Plotly\n            \n            for i, (name, result) in enumerate(results_dict.items()):\n                color = colors[i % len(colors)]\n                \n                if 'diagnostics' in result:\n                    diag = result['diagnostics']\n                    \n                    # Acceptance rate\n                    if 'acceptance_rate' in diag:\n                        fig.add_trace(\n                            go.Bar(x=[name], y=[diag['acceptance_rate']],\n                                 name=name, marker_color=color),\n                            row=1, col=1\n                        )\n                    \n                    # ESS per second\n                    if 'ess_per_second' in diag:\n                        fig.add_trace(\n                            go.Bar(x=[name], y=[diag['ess_per_second']],\n                                 name=name, marker_color=color,\n                                 showlegend=False),\n                            row=1, col=2\n                        )\n                    \n                    # R-hat\n                    if 'r_hat' in diag:\n                        fig.add_trace(\n                            go.Box(y=diag['r_hat'], name=name,\n                                 marker_color=color, showlegend=False),\n                            row=2, col=1\n                        )\n                    \n                    # Autocorrelation\n                    if 'samples' in result:\n                        samples = result['samples']\n                        if samples.ndim == 3:\n                            chain_data = samples[0, :, 0]\n                        else:\n                            chain_data = samples[:, 0]\n                        \n                        acf = [pd.Series(chain_data).autocorr(lag=k) \n                               for k in range(min(50, len(chain_data)//4))]\n                        fig.add_trace(\n                            go.Scatter(y=acf, mode='lines', name=name,\n                                     line=dict(color=color), showlegend=False),\n                            row=2, col=2\n                        )\n            \n            fig.update_layout(height=800, showlegend=True)\n            fig.show()\n            \n            # Summary table\n            summary_data = []\n            for name, result in results_dict.items():\n                if 'diagnostics' in result:\n                    diag = result['diagnostics']\n                    summary_data.append({\n                        'Sampler': name,\n                        'Acceptance Rate': diag.get('acceptance_rate', 'N/A'),\n                        'Mean ESS': diag.get('mean_ess', 'N/A'),\n                        'Min R-hat': diag.get('min_r_hat', 'N/A'),\n                        'Max R-hat': diag.get('max_r_hat', 'N/A'),\n                        'Runtime (s)': diag.get('runtime', 'N/A')\n                    })\n            \n            display(pd.DataFrame(summary_data))\n        \n        display(output)\n\n# Create diagnostic analyzer\ndiag = DiagnosticAnalyzer()\n\n# Example analysis\nprint(\"Running diagnostic analysis on synthetic data...\")\ndiag.analyze_convergence(synthetic_data)",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Rapid Prototyping\n\nThe `AnalysisSandbox` provides a flexible environment for quick experiments and custom analyses.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class AnalysisSandbox:\n    \"\"\"Sandbox environment for rapid prototyping and experimentation.\"\"\"\n    \n    def __init__(self):\n        self.data_store = {}\n        self.plot_store = []\n        self.code_history = []\n        \n    def create_sandbox(self):\n        \"\"\"Create interactive sandbox interface.\"\"\"\n        # Code editor\n        code_area = widgets.Textarea(\n            value='# Enter your analysis code here\\n# Available variables: data_store, samples\\n\\n',\n            layout=widgets.Layout(width='100%', height='200px'),\n            description='Code:'\n        )\n        \n        # Variable inspector\n        var_output = widgets.Output()\n        \n        # Plot output\n        plot_output = widgets.Output()\n        \n        # Console output\n        console_output = widgets.Output()\n        \n        # Control buttons\n        run_btn = widgets.Button(description='Run Code', button_style='primary')\n        clear_btn = widgets.Button(description='Clear Output', button_style='warning')\n        save_btn = widgets.Button(description='Save Code', button_style='success')\n        \n        def update_variables():\n            \"\"\"Update variable inspector.\"\"\"\n            with var_output:\n                var_output.clear_output()\n                print(\"=== Data Store ===\")\n                for key, value in self.data_store.items():\n                    if isinstance(value, np.ndarray):\n                        print(f\"{key}: ndarray {value.shape}\")\n                    elif isinstance(value, pd.DataFrame):\n                        print(f\"{key}: DataFrame {value.shape}\")\n                    else:\n                        print(f\"{key}: {type(value).__name__}\")\n        \n        def run_code(b):\n            \"\"\"Execute code in sandbox.\"\"\"\n            with console_output:\n                console_output.clear_output()\n                plot_output.clear_output()\n                \n                # Prepare namespace\n                namespace = {\n                    'np': np,\n                    'pd': pd,\n                    'plt': plt,\n                    'sns': sns,\n                    'go': go,\n                    'px': px,\n                    'data_store': self.data_store,\n                    'samples': viz.samples,\n                    'loader': loader,\n                    'viz': viz,\n                    'diag': diag\n                }\n                \n                try:\n                    # Capture plots\n                    with plot_output:\n                        exec(code_area.value, namespace)\n                    \n                    # Update data store if modified\n                    self.data_store = namespace['data_store']\n                    update_variables()\n                    \n                    # Save to history\n                    self.code_history.append({\n                        'timestamp': datetime.now(),\n                        'code': code_area.value,\n                        'success': True\n                    })\n                    \n                    print(\"✅ Code executed successfully\")\n                    \n                except Exception as e:\n                    print(f\"❌ Error: {str(e)}\")\n                    import traceback\n                    traceback.print_exc()\n                    \n                    self.code_history.append({\n                        'timestamp': datetime.now(),\n                        'code': code_area.value,\n                        'success': False,\n                        'error': str(e)\n                    })\n        \n        def clear_output(b):\n            \"\"\"Clear all outputs.\"\"\"\n            console_output.clear_output()\n            plot_output.clear_output()\n        \n        def save_code(b):\n            \"\"\"Save code snippet.\"\"\"\n            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n            filename = f'sandbox_code_{timestamp}.py'\n            \n            with console_output:\n                print(f\"Code saved to: {filename}\")\n                # In practice, save to file\n                print(\"(File saving not implemented in demo)\")\n        \n        # Connect buttons\n        run_btn.on_click(run_code)\n        clear_btn.on_click(clear_output)\n        save_btn.on_click(save_code)\n        \n        # Code snippets dropdown\n        snippets = {\n            'Basic Statistics': '''# Calculate basic statistics\nif samples is not None:\n    print(\"Mean:\", np.mean(samples))\n    print(\"Std:\", np.std(samples))\n    print(\"Shape:\", samples.shape)\n''',\n            'Quick Histogram': '''# Create histogram\nif samples is not None:\n    data = samples.flatten() if samples.ndim > 1 else samples\n    plt.figure(figsize=(8, 6))\n    plt.hist(data[:1000], bins=50, alpha=0.7)\n    plt.title('Sample Distribution')\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.show()\n''',\n            'Correlation Matrix': '''# Compute and plot correlation matrix\nif samples is not None:\n    if samples.ndim == 3:\n        data = samples[0]  # First chain\n    else:\n        data = samples\n    \n    if data.shape[1] > 1:\n        corr = np.corrcoef(data.T)\n        plt.figure(figsize=(8, 6))\n        sns.heatmap(corr, cmap='coolwarm', center=0)\n        plt.title('Correlation Matrix')\n        plt.show()\n''',\n            'Custom Analysis': '''# Custom analysis template\n# Store results in data_store for later use\n\nresult = {}\n\n# Your analysis here\nif samples is not None:\n    result['mean'] = np.mean(samples, axis=0)\n    result['std'] = np.std(samples, axis=0)\n    \n    # Store in data_store\n    data_store['my_analysis'] = result\n    \n    print(\"Analysis complete!\")\n    print(\"Results stored in data_store['my_analysis']\")\n''',\n            'Interactive Plot': '''# Create interactive plot with Plotly\nif samples is not None:\n    if samples.ndim >= 2:\n        data = samples[:1000, 0] if samples.ndim == 2 else samples[0, :1000, 0]\n    else:\n        data = samples[:1000]\n    \n    fig = go.Figure()\n    fig.add_trace(go.Scatter(y=data, mode='lines', name='Samples'))\n    fig.update_layout(\n        title='Sample Trace',\n        xaxis_title='Iteration',\n        yaxis_title='Value',\n        height=400\n    )\n    fig.show()\n'''\n        }\n        \n        snippet_dropdown = widgets.Dropdown(\n            options=['Select snippet...'] + list(snippets.keys()),\n            description='Snippets:'\n        )\n        \n        def load_snippet(change):\n            if change['new'] != 'Select snippet...' and change['new'] in snippets:\n                code_area.value = snippets[change['new']]\n        \n        snippet_dropdown.observe(load_snippet, 'value')\n        \n        # Initial variable display\n        update_variables()\n        \n        # Layout\n        display(widgets.VBox([\n            widgets.HBox([snippet_dropdown]),\n            code_area,\n            widgets.HBox([run_btn, clear_btn, save_btn]),\n            widgets.HBox([\n                widgets.VBox([widgets.HTML('<b>Variables</b>'), var_output], \n                           layout=widgets.Layout(width='30%')),\n                widgets.VBox([widgets.HTML('<b>Console</b>'), console_output], \n                           layout=widgets.Layout(width='70%'))\n            ]),\n            widgets.VBox([widgets.HTML('<b>Plots</b>'), plot_output])\n        ]))\n    \n    def load_experiment_data(self, experiment_path):\n        \"\"\"Quick loader for experiment data.\"\"\"\n        try:\n            data = loader.load_samples(experiment_path)\n            self.data_store['loaded_data'] = data\n            print(f\"✅ Loaded data from {experiment_path}\")\n            return data\n        except Exception as e:\n            print(f\"❌ Error loading data: {str(e)}\")\n            return None\n\n# Create sandbox\nsandbox = AnalysisSandbox()\nsandbox.create_sandbox()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Documentation and Insights\n\nThe `InsightRecorder` helps track findings and generate documentation during analysis.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class InsightRecorder:\n    \"\"\"Tool for recording insights and generating documentation.\"\"\"\n    \n    def __init__(self):\n        self.insights = []\n        self.figures = []\n        self.current_session = {\n            'start_time': datetime.now(),\n            'insights': [],\n            'figures': []\n        }\n    \n    def create_recorder(self):\n        \"\"\"Create interactive insight recording interface.\"\"\"\n        # Insight entry\n        insight_text = widgets.Textarea(\n            placeholder='Enter your insight or observation...',\n            layout=widgets.Layout(width='100%', height='100px')\n        )\n        \n        # Category selection\n        category_dropdown = widgets.Dropdown(\n            options=['General', 'Convergence', 'Performance', 'Anomaly', 'Hypothesis', 'TODO'],\n            value='General',\n            description='Category:'\n        )\n        \n        # Priority\n        priority_slider = widgets.IntSlider(\n            value=3, min=1, max=5,\n            description='Priority:'\n        )\n        \n        # Insight list\n        insights_output = widgets.Output()\n        \n        # Buttons\n        add_btn = widgets.Button(description='Add Insight', button_style='primary')\n        export_btn = widgets.Button(description='Export Report', button_style='success')\n        clear_btn = widgets.Button(description='Clear Current', button_style='warning')\n        \n        def update_insights_display():\n            \"\"\"Update the insights display.\"\"\"\n            with insights_output:\n                insights_output.clear_output()\n                \n                if not self.current_session['insights']:\n                    print(\"No insights recorded yet.\")\n                    return\n                \n                # Group by category\n                from collections import defaultdict\n                by_category = defaultdict(list)\n                \n                for insight in self.current_session['insights']:\n                    by_category[insight['category']].append(insight)\n                \n                # Display\n                for category, items in by_category.items():\n                    print(f\"\\n### {category}\")\n                    print(\"-\" * 40)\n                    \n                    for item in sorted(items, key=lambda x: x['priority'], reverse=True):\n                        timestamp = item['timestamp'].strftime('%H:%M:%S')\n                        priority_stars = \"⭐\" * item['priority']\n                        print(f\"[{timestamp}] {priority_stars}\")\n                        print(f\"  {item['text']}\")\n                        if 'figure' in item:\n                            print(f\"  📊 Attached figure: {item['figure']}\")\n                        print()\n        \n        def add_insight(b):\n            \"\"\"Add new insight.\"\"\"\n            if not insight_text.value.strip():\n                return\n            \n            insight = {\n                'timestamp': datetime.now(),\n                'text': insight_text.value,\n                'category': category_dropdown.value,\n                'priority': priority_slider.value\n            }\n            \n            # Check if there's a current figure\n            if plt.get_fignums():\n                fig_name = f\"fig_{len(self.current_session['figures'])}.png\"\n                insight['figure'] = fig_name\n                self.current_session['figures'].append({\n                    'name': fig_name,\n                    'figure': plt.gcf()\n                })\n            \n            self.current_session['insights'].append(insight)\n            self.insights.append(insight)\n            \n            # Clear input\n            insight_text.value = ''\n            \n            # Update display\n            update_insights_display()\n        \n        def export_report(b):\n            \"\"\"Export insights as markdown report.\"\"\"\n            report = []\n            report.append(\"# Analysis Report\")\n            report.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n            report.append(f\"Session Duration: {datetime.now() - self.current_session['start_time']}\")\n            report.append(\"\")\n            \n            # Summary\n            report.append(\"## Summary\")\n            report.append(f\"- Total insights: {len(self.current_session['insights'])}\")\n            report.append(f\"- Figures generated: {len(self.current_session['figures'])}\")\n            report.append(\"\")\n            \n            # Insights by category\n            from collections import defaultdict\n            by_category = defaultdict(list)\n            \n            for insight in self.current_session['insights']:\n                by_category[insight['category']].append(insight)\n            \n            for category, items in by_category.items():\n                report.append(f\"## {category}\")\n                \n                for item in sorted(items, key=lambda x: x['priority'], reverse=True):\n                    timestamp = item['timestamp'].strftime('%Y-%m-%d %H:%M:%S')\n                    priority = \"Priority: \" + \"⭐\" * item['priority']\n                    \n                    report.append(f\"### {timestamp} - {priority}\")\n                    report.append(item['text'])\n                    \n                    if 'figure' in item:\n                        report.append(f\"\\n![{item['figure']}](./{item['figure']})\")\n                    \n                    report.append(\"\")\n            \n            # Display report\n            from IPython.display import Markdown\n            display(Markdown('\\n'.join(report)))\n            \n            # Save to file\n            filename = f\"analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md\"\n            print(f\"\\nReport would be saved to: {filename}\")\n        \n        def clear_current(b):\n            \"\"\"Clear current session.\"\"\"\n            self.current_session = {\n                'start_time': datetime.now(),\n                'insights': [],\n                'figures': []\n            }\n            update_insights_display()\n        \n        # Connect buttons\n        add_btn.on_click(add_insight)\n        export_btn.on_click(export_report)\n        clear_btn.on_click(clear_current)\n        \n        # Initial display\n        update_insights_display()\n        \n        # Layout\n        display(widgets.VBox([\n            widgets.HTML('<h3>Record Analysis Insights</h3>'),\n            widgets.HBox([category_dropdown, priority_slider]),\n            insight_text,\n            widgets.HBox([add_btn, export_btn, clear_btn]),\n            widgets.HTML('<h4>Current Session Insights</h4>'),\n            insights_output\n        ]))\n    \n    def quick_note(self, text, category='General', priority=3):\n        \"\"\"Quick method to add an insight programmatically.\"\"\"\n        insight = {\n            'timestamp': datetime.now(),\n            'text': text,\n            'category': category,\n            'priority': priority\n        }\n        \n        self.current_session['insights'].append(insight)\n        self.insights.append(insight)\n        \n        print(f\"✅ Insight recorded: {text[:50]}...\")\n    \n    def attach_current_figure(self, name=None):\n        \"\"\"Attach the current matplotlib figure to the last insight.\"\"\"\n        if plt.get_fignums() and self.current_session['insights']:\n            if name is None:\n                name = f\"fig_{len(self.current_session['figures'])}.png\"\n            \n            self.current_session['figures'].append({\n                'name': name,\n                'figure': plt.gcf()\n            })\n            \n            self.current_session['insights'][-1]['figure'] = name\n            print(f\"📊 Figure attached: {name}\")\n\n# Create insight recorder\nrecorder = InsightRecorder()\nrecorder.create_recorder()\n\n# Example usage\nrecorder.quick_note(\"Synthetic data shows expected normal distribution\", \"General\", 3)",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Export and Reproducibility\n\nThe `ExportManager` handles exporting results in various formats for publications and reproducibility.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class ExportManager:\n    \"\"\"Manage export of figures and results for publications.\"\"\"\n    \n    def __init__(self, export_dir='../results/figures'):\n        self.export_dir = Path(export_dir)\n        self.export_dir.mkdir(parents=True, exist_ok=True)\n        self.exported_items = []\n        \n    def create_export_interface(self):\n        \"\"\"Create interactive export interface.\"\"\"\n        # Figure selection\n        fig_name = widgets.Text(\n            placeholder='figure_name',\n            description='Name:'\n        )\n        \n        # Format selection\n        format_select = widgets.SelectMultiple(\n            options=['png', 'pdf', 'svg', 'eps'],\n            value=['png', 'pdf'],\n            description='Formats:',\n            rows=4\n        )\n        \n        # Resolution\n        dpi_slider = widgets.IntSlider(\n            value=300, min=72, max=600, step=50,\n            description='DPI:'\n        )\n        \n        # Publication presets\n        preset_dropdown = widgets.Dropdown(\n            options=[\n                'Custom',\n                'Journal (300dpi, PDF+PNG)',\n                'Presentation (150dpi, PNG)',\n                'Web (72dpi, PNG+SVG)',\n                'Print (600dpi, PDF+EPS)'\n            ],\n            value='Custom',\n            description='Preset:'\n        )\n        \n        # Export log\n        export_log = widgets.Output()\n        \n        # Buttons\n        export_current_btn = widgets.Button(\n            description='Export Current Figure',\n            button_style='primary'\n        )\n        \n        export_all_btn = widgets.Button(\n            description='Export All Figures',\n            button_style='warning'\n        )\n        \n        generate_latex_btn = widgets.Button(\n            description='Generate LaTeX',\n            button_style='success'\n        )\n        \n        def apply_preset(change):\n            \"\"\"Apply export preset.\"\"\"\n            preset = change['new']\n            if preset == 'Journal (300dpi, PDF+PNG)':\n                format_select.value = ['png', 'pdf']\n                dpi_slider.value = 300\n            elif preset == 'Presentation (150dpi, PNG)':\n                format_select.value = ['png']\n                dpi_slider.value = 150\n            elif preset == 'Web (72dpi, PNG+SVG)':\n                format_select.value = ['png', 'svg']\n                dpi_slider.value = 72\n            elif preset == 'Print (600dpi, PDF+EPS)':\n                format_select.value = ['pdf', 'eps']\n                dpi_slider.value = 600\n        \n        preset_dropdown.observe(apply_preset, 'value')\n        \n        def export_figure(fig, name, formats, dpi):\n            \"\"\"Export a single figure.\"\"\"\n            exported_files = []\n            \n            for fmt in formats:\n                filename = f\"{name}.{fmt}\"\n                filepath = self.export_dir / filename\n                \n                # Configure matplotlib for better export\n                if fmt in ['pdf', 'eps']:\n                    fig.savefig(filepath, format=fmt, dpi=dpi, \n                              bbox_inches='tight', pad_inches=0.1)\n                else:\n                    fig.savefig(filepath, format=fmt, dpi=dpi,\n                              bbox_inches='tight', pad_inches=0.1,\n                              facecolor='white', edgecolor='none')\n                \n                exported_files.append(filepath)\n                \n                self.exported_items.append({\n                    'name': name,\n                    'format': fmt,\n                    'dpi': dpi,\n                    'path': filepath,\n                    'timestamp': datetime.now()\n                })\n            \n            return exported_files\n        \n        def export_current(b):\n            \"\"\"Export current matplotlib figure.\"\"\"\n            with export_log:\n                if not plt.get_fignums():\n                    print(\"❌ No active figure found.\")\n                    return\n                \n                if not fig_name.value:\n                    print(\"❌ Please enter a figure name.\")\n                    return\n                \n                fig = plt.gcf()\n                exported = export_figure(\n                    fig, fig_name.value,\n                    list(format_select.value),\n                    dpi_slider.value\n                )\n                \n                print(f\"✅ Exported {fig_name.value}:\")\n                for path in exported:\n                    print(f\"   - {path}\")\n        \n        def export_all(b):\n            \"\"\"Export all open figures.\"\"\"\n            with export_log:\n                figs = [plt.figure(num) for num in plt.get_fignums()]\n                \n                if not figs:\n                    print(\"❌ No figures to export.\")\n                    return\n                \n                print(f\"Exporting {len(figs)} figures...\")\n                \n                for i, fig in enumerate(figs):\n                    name = f\"{fig_name.value or 'figure'}_{i+1}\"\n                    exported = export_figure(\n                        fig, name,\n                        list(format_select.value),\n                        dpi_slider.value\n                    )\n                    print(f\"✅ Exported {name}\")\n                \n                print(f\"\\nTotal files exported: {len(figs) * len(format_select.value)}\")\n        \n        def generate_latex(b):\n            \"\"\"Generate LaTeX code for figures.\"\"\"\n            with export_log:\n                print(\"% LaTeX code for figures\")\n                print(\"% Add to preamble: \\\\usepackage{graphicx}\")\n                print(\"% Add to preamble: \\\\usepackage{subcaption} % for subfigures\\n\")\n                \n                # Group by base name\n                from collections import defaultdict\n                by_name = defaultdict(list)\n                \n                for item in self.exported_items:\n                    if item['format'] == 'pdf':  # Prefer PDF for LaTeX\n                        by_name[item['name']].append(item)\n                \n                for name, items in by_name.items():\n                    print(f\"% Figure: {name}\")\n                    print(\"\\\\begin{figure}[htbp]\")\n                    print(\"    \\\\centering\")\n                    print(f\"    \\\\includegraphics[width=0.8\\\\textwidth]{{{name}.pdf}}\")\n                    print(f\"    \\\\caption{{Caption for {name}}}\")\n                    print(f\"    \\\\label{{fig:{name}}}\")\n                    print(\"\\\\end{figure}\\n\")\n                \n                # Also generate a comparison figure\n                if len(by_name) > 1:\n                    print(\"% Comparison figure with subfigures\")\n                    print(\"\\\\begin{figure}[htbp]\")\n                    print(\"    \\\\centering\")\n                    \n                    names = list(by_name.keys())[:4]  # Max 4 subfigures\n                    width = 0.45 if len(names) <= 2 else 0.45\n                    \n                    for i, name in enumerate(names):\n                        if i % 2 == 0 and i > 0:\n                            print(\"    \\\\\\\\\")\n                        print(f\"    \\\\begin{{subfigure}}[b]{{{width}\\\\textwidth}}\")\n                        print(f\"        \\\\includegraphics[width=\\\\textwidth]{{{name}.pdf}}\")\n                        print(f\"        \\\\caption{{{name}}}\")\n                        print(\"    \\\\end{subfigure}\")\n                        if i % 2 == 0 and i < len(names) - 1:\n                            print(\"    \\\\hfill\")\n                    \n                    print(\"    \\\\caption{Comparison of results}\")\n                    print(\"    \\\\label{fig:comparison}\")\n                    print(\"\\\\end{figure}\")\n        \n        # Connect buttons\n        export_current_btn.on_click(export_current)\n        export_all_btn.on_click(export_all)\n        generate_latex_btn.on_click(generate_latex)\n        \n        # Display interface\n        display(widgets.VBox([\n            widgets.HTML('<h3>Export Manager</h3>'),\n            widgets.HBox([preset_dropdown]),\n            widgets.HBox([fig_name, format_select]),\n            widgets.HBox([dpi_slider]),\n            widgets.HBox([export_current_btn, export_all_btn, generate_latex_btn]),\n            widgets.HTML('<h4>Export Log</h4>'),\n            export_log\n        ]))\n    \n    def create_publication_figure(self, width=6, height=4, style='paper'):\n        \"\"\"Create a figure with publication-ready settings.\"\"\"\n        # Set font sizes\n        if style == 'paper':\n            plt.rcParams.update({\n                'font.size': 10,\n                'axes.titlesize': 11,\n                'axes.labelsize': 10,\n                'xtick.labelsize': 9,\n                'ytick.labelsize': 9,\n                'legend.fontsize': 9,\n                'figure.titlesize': 12\n            })\n        elif style == 'presentation':\n            plt.rcParams.update({\n                'font.size': 14,\n                'axes.titlesize': 16,\n                'axes.labelsize': 14,\n                'xtick.labelsize': 12,\n                'ytick.labelsize': 12,\n                'legend.fontsize': 12,\n                'figure.titlesize': 18\n            })\n        \n        # Create figure\n        fig, ax = plt.subplots(figsize=(width, height))\n        \n        # Set properties\n        ax.spines['top'].set_visible(False)\n        ax.spines['right'].set_visible(False)\n        \n        return fig, ax\n    \n    def save_session_metadata(self):\n        \"\"\"Save metadata about the export session.\"\"\"\n        metadata = {\n            'timestamp': datetime.now().isoformat(),\n            'exported_items': self.exported_items,\n            'export_dir': str(self.export_dir),\n            'total_exports': len(self.exported_items)\n        }\n        \n        metadata_path = self.export_dir / 'export_metadata.json'\n        with open(metadata_path, 'w') as f:\n            json.dump(metadata, f, indent=2, default=str)\n        \n        print(f\"✅ Metadata saved to {metadata_path}\")\n        return metadata\n\n# Create export manager\nexporter = ExportManager()\nexporter.create_export_interface()\n\n# Example: Create publication-ready figure\nfig, ax = exporter.create_publication_figure(width=6, height=4, style='paper')\nax.plot(np.random.randn(100).cumsum())\nax.set_xlabel('Iteration')\nax.set_ylabel('Value')\nax.set_title('Example Publication Figure')\nplt.show()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Summary\n\nThis notebook provides a comprehensive toolkit for interactive exploratory analysis of lattice Gaussian MCMC experiments:\n\n### Key Components:\n\n1. **DataLoader**: Flexible data loading with caching and format detection\n2. **InteractiveVisualizer**: Dynamic visualization tools for chains, distributions, and diagnostics\n3. **DiagnosticAnalyzer**: Comprehensive MCMC diagnostics (R-hat, ESS, Geweke, etc.)\n4. **AnalysisSandbox**: Rapid prototyping environment with code execution\n5. **InsightRecorder**: Documentation and insight tracking system\n6. **ExportManager**: Publication-ready figure export with LaTeX generation\n\n### Usage Tips:\n\n- Start by loading your experimental data with the DataLoader\n- Use the InteractiveVisualizer for initial exploration\n- Run diagnostic analysis to verify convergence\n- Experiment with custom analyses in the Sandbox\n- Record important findings with the InsightRecorder\n- Export final figures with the ExportManager\n\n### Next Steps:\n\n1. Load actual experimental results\n2. Compare different sampling algorithms\n3. Generate publication figures\n4. Export insights and create reports",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Quick reference for all tools\nprint(\"=== Quick Reference ===\")\nprint(\"\\n1. Load data:\")\nprint(\"   loader.create_interactive_loader()\")\nprint(\"   data = loader.load_samples('path/to/data.npz')\")\nprint(\"\\n2. Visualize:\")\nprint(\"   viz.set_samples(data)\")\nprint(\"   viz.trace_plot_interactive()\")\nprint(\"   viz.pairwise_scatter()\")\nprint(\"   viz.spectral_density_plot()\")\nprint(\"\\n3. Diagnose:\")\nprint(\"   diag.analyze_convergence(data)\")\nprint(\"   diag.compare_samplers(results_dict)\")\nprint(\"\\n4. Sandbox:\")\nprint(\"   sandbox.create_sandbox()\")\nprint(\"   sandbox.load_experiment_data('path/to/data')\")\nprint(\"\\n5. Record insights:\")\nprint(\"   recorder.quick_note('My insight', 'Category', priority=5)\")\nprint(\"   recorder.attach_current_figure()\")\nprint(\"\\n6. Export:\")\nprint(\"   exporter.create_export_interface()\")\nprint(\"   exporter.save_session_metadata()\")",
   "metadata": {},
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}